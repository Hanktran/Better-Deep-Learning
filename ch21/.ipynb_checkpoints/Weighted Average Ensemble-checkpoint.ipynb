{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for coefficients in a weighted average ensemble\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import tensordot\n",
    "from numpy.linalg import norm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on dataset\n",
    "def fit_model(trainX, trainY):\n",
    "    trainY_enc = to_categorical(trainY)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY_enc, epochs=500, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, weights, testX):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(testX) for model in members]\n",
    "    yhats = array(yhats)\n",
    "    # weighted sum across ensemble members\n",
    "    summed = tensordot(yhats, weights, axes=((0), (0)))\n",
    "    # argmax across classes\n",
    "    result = argmax(summed, axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_ensemble(members, weights, testX, testY):\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(members, weights, testX)\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testY, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search weights\n",
    "def grid_search(members, testX, testY):\n",
    "    # define weights to consider\n",
    "    w = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    best_score, best_weights = 0.0, None\n",
    "    # iterate all possible combinations (cartesian product)\n",
    "    for weights in product(w, repeat=len(members)):\n",
    "        # skip if all weights are equal\n",
    "        if len(set(weights)) == 1:\n",
    "            continue\n",
    "        # hack, normalize weight vector\n",
    "        weights = normalize(weights)\n",
    "        # evaluate weights\n",
    "        score = evaluate_ensemble(members, weights, testX, testY)\n",
    "        if score > best_score:\n",
    "            best_score, best_weights = score, weights\n",
    "            print('> %s %.3f' % (best_weights, best_score))\n",
    "    return list(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "X, Y = make_blobs(n_samples=1100, centers=3, n_features=2,\n",
    "                 cluster_std=2, random_state=2)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainY, testY = Y[:n_train], Y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit all models\n",
    "n_members = 5\n",
    "members = [fit_model(trainX, trainY) for _ in range(n_members)]\n",
    "# evaluate each single model on the test set\n",
    "testY_enc = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_members):\n",
    "    _, test_acc = members[i].evaluate(testX, testY_enc, verbose=0)\n",
    "    print('Model %d: %.3f' % (i+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate averaging ensemble (equal weights)\n",
    "weights = [1.0 / n_members for _ in range(n_members)]\n",
    "score = evaluate_ensemble(members, weights, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search weights\n",
    "weights = grid_search(members, testX, testY)\n",
    "score = evaluate_ensemble(members, weights, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
