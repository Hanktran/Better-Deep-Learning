{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare standalone mlp model performance to transfer learning\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "    # generate samples\n",
    "    X, Y = make_blobs(n_samples=1000, centers=3, n_features=2, random_state=seed)\n",
    "    # one hot encode output variable\n",
    "    Y = to_categorical(Y)\n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainY, testY = Y[:n_train], Y[n_train:]\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainY):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu',\n",
    "                   kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                 metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=100, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated evaluation of a standalone model\n",
    "def eval_standalone_model(trainX, trainY, testX, testY, n_repeats):\n",
    "    scores = list()\n",
    "    for _ in range(n_repeats):\n",
    "        # define and fit a new model on the train dataset\n",
    "        model = fit_model(trainX, trainY)\n",
    "        # evaluate model on test dataset\n",
    "        _, test_acc = model.evaluate(testX, testY, verbose=0)\n",
    "        scores.append(test_acc)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated evaluation of a model with transfer learning\n",
    "def eval_transfer_model(trainX, trainY, testX, testY, n_fixed, n_repeats):\n",
    "    scores = list()\n",
    "    for _ in range(n_repeats):\n",
    "        # load model\n",
    "        model = load_model('model_1.h5')\n",
    "        # mark layer weights as fixed or not trainable\n",
    "        for i in range(n_fixed):\n",
    "            model.layers[i].trainable = False\n",
    "        # re-compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                     metrics=['accuracy'])\n",
    "        # fit model on train dataset\n",
    "        model.fit(trainX, trainY, epochs=100, verbose=0)\n",
    "        # evaluate model on test dataset\n",
    "        _, test_acc = model.evaluate(testX, testY, verbose=0)\n",
    "        scores.append(test_acc)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for problem 2\n",
    "trainX, trainY, testX, testY = samples_for_seed(2)\n",
    "n_repeats = 30\n",
    "dists, dist_labels = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1222 06:37:18.843013  6504 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1222 06:37:18.868916  6504 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:529: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1222 06:37:18.872416  6504 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4420: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1222 06:37:18.960206  6504 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1222 06:37:19.002522  6504 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3564: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1222 06:37:19.212146  6504 deprecation.py:323] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1222 06:37:19.320020  6504 deprecation_wrapper.py:119] From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1021: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone 0.932 (0.050)\n"
     ]
    }
   ],
   "source": [
    "# repeated evaluation of standalone model\n",
    "standalone_scores = eval_standalone_model(trainX, trainY, testX, testY, n_repeats)\n",
    "print('Standalone %.3f (%.3f)' % (mean(standalone_scores), std(standalone_scores)))\n",
    "dists.append(standalone_scores)\n",
    "dist_labels.append('standalone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer (fixed=0) 0.709 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# repeated evaluation of transfer learning model, vary fixed layers\n",
    "n_fixed = 3\n",
    "for i in range(n_fixed):\n",
    "    scores = eval_transfer_model(trainX, trainY, testX, testY, i, n_repeats)\n",
    "    print('Transfer (fixed=%s) %.3f (%.3f)' % (i, mean(scores), std(scores)))\n",
    "    dists.append(scores)\n",
    "    dist_labels.append('transfer f=' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box and whisker plot of score distributions\n",
    "pyplot.boxplot(dists, labels=dist_labels)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
